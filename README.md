# locaLLM_bot

Telegram Bot для Ollama

Простой Telegram бот на Go для работы с Ollama LLM. Бот отправляет запросы пользователей в Ollama API и возвращает ответы.

## Особенности

- Использует только стандартную библиотеку Go (без внешних зависимостей)
- Собирается в один исполняемый файл
- Работает без базы данных
- Автоматически разбивает длинные ответы на несколько сообщений
- Обрабатывает ошибки с детальными сообщениями
- Graceful shutdown при получении сигнала завершения

## Требования

- Go 1.21 или выше
- Доступ к серверу с Ollama
- Токен Telegram бота

## Установка

1. Клонируйте репозиторий или скачайте файлы проекта

2. Установите переменные окружения. Скопируйте `env.example` и заполните значения:

```bash
# Windows (PowerShell)
$env:TELEGRAM_BOT_TOKEN="your_bot_token_here"
$env:OLLAMA_URL="http://YOUR_OLLAMA_HOST:11434"
$env:OLLAMA_MODEL="your_model_name"

# Linux/Mac
export TELEGRAM_BOT_TOKEN="your_bot_token_here"
export OLLAMA_URL="http://YOUR_OLLAMA_HOST:11434"
export OLLAMA_MODEL="your_model_name"
```

3. Соберите проект:

```bash
go build -o telegram-ollama-bot
```

Или запустите напрямую:

```bash
go run .
```

## Получение токена Telegram бота

1. Откройте Telegram и найдите [@BotFather](https://t.me/BotFather)
2. Отправьте команду `/newbot`
3. Следуйте инструкциям для создания бота
4. Скопируйте полученный токен и установите его в переменную окружения `TELEGRAM_BOT_TOKEN`

## Использование

После запуска бот будет:

- Отвечать на команду `/start` приветственным сообщением
- Отвечать на команду `/help` справкой
- Обрабатывать любые текстовые сообщения, отправляя их в Ollama и возвращая ответ

## Структура проекта

```
local-llm/
├── main.go              # Основной файл бота
├── ollama.go            # Клиент для работы с Ollama API
├── telegram.go          # Обработка Telegram сообщений
├── utils.go             # Утилиты (разбиение сообщений)
├── go.mod               # Go модуль
├── env.example          # Пример конфигурации
└── README.md            # Этот файл
```

## Развертывание на сервере

1. Соберите бинарник на вашей машине или на сервере:

```bash
go build -o telegram-ollama-bot
```

2. Скопируйте исполняемый файл на сервер с Ollama

3. Установите переменные окружения на сервере

4. Запустите бота:

```bash
./telegram-ollama-bot
```

Для запуска в фоне можно использовать `nohup` или systemd:

```bash
nohup ./telegram-ollama-bot > bot.log 2>&1 &
```

Или создайте systemd сервис для автоматического запуска.

## Переменные окружения

- `TELEGRAM_BOT_TOKEN` (обязательно) - токен Telegram бота, полученный от @BotFather
- `OLLAMA_URL` (опционально) - URL Ollama сервера в формате `http://IP_АДРЕС:ПОРТ` или `http://ДОМЕН:ПОРТ`. По умолчанию: `http://localhost:11434`. Пример: `http://192.168.1.100:11434`
- `OLLAMA_MODEL` (опционально) - название модели Ollama, которую нужно использовать. По умолчанию: `gemma3:1b`. Пример: `llama2`, `mistral`

## Обработка ошибок

Бот обрабатывает следующие типы ошибок:

- Ошибки подключения к Ollama API
- Ошибки парсинга JSON
- Ошибки отправки сообщений в Telegram
- Таймауты запросов (таймаут для Ollama API установлен на 8 минут)

Все ошибки логируются и отправляются пользователю с детальным описанием. При ошибках получения обновлений от Telegram API бот автоматически повторяет запрос с задержкой 5 секунд.

## Ограничения и особенности

- Telegram имеет лимит на длину сообщения (~4096 символов). Длинные ответы автоматически разбиваются на несколько сообщений с сохранением читаемости (разбиение по переносам строк и пробелам).
- Rate limits Telegram API: между отправкой частей длинного ответа есть небольшая задержка (100ms).
- Таймаут ожидания ответа от Ollama: 8 минут (480 секунд). Это позволяет обрабатывать длинные запросы к большим моделям.
- Graceful shutdown: бот корректно завершает работу при получении сигнала SIGTERM или SIGINT.

## Лицензия

Этот проект создан для личного использования.
